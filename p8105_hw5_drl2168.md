P8105 Homework 5
================
Derek Lamb
2023-11-12

``` r
library(tidyverse)

knitr::opts_chunk$set(
  fig.width = 6,
  out.width = "90%"
)

theme_set(theme_bw() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

# Problem 1

I imported the data, noting that missing data are coded as `Unknown`. I
also corrected a typo, where a homicide in Tulsa, OK was misclassified
as in AL, and corrected the state representations (Wisconsin was `wi`).
I then summarized the homicide data by city and state.

``` r
df_homicide <- read_csv("data/homicide-data.csv", 
                        na = "Unknown") |> 
  mutate(
    state = case_when(
      city == "Tulsa" ~ "OK",
      city != "Tulsa" ~ state),
    state = str_to_upper(state),
    city_state = str_c(city, ", ", state)
    ) |> 
  group_by(city_state) |> 
  summarize(n_homicide = n(),
            n_unsolved = sum(disposition %in% c("
                                                Closed without arrest",
                                                "Open/No arrest")))
```

    ## Warning: One or more parsing issues, call `problems()` on your data frame for details,
    ## e.g.:
    ##   dat <- vroom(...)
    ##   problems(dat)

    ## Rows: 52179 Columns: 12
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (8): uid, victim_last, victim_first, victim_race, victim_sex, city, stat...
    ## dbl (4): reported_date, victim_age, lat, lon
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

Within Baltimore, MD, I calculated the proportion of unsolved cases and
a confidence interval for this value.

``` r
df_homicide |> 
  filter(city_state == "Baltimore, MD") |> 
  mutate(df = broom::tidy(prop.test(x = n_unsolved, 
                                    n = n_homicide,
                                    p = 0.5,
                                    alternative = "two.sided")))
```

    ## # A tibble: 1 × 4
    ##   city_state    n_homicide n_unsolved df$estimate $statistic $p.value $parameter
    ##   <chr>              <int>      <int>       <dbl>      <dbl>    <dbl>      <int>
    ## 1 Baltimore, MD       2827       1673       0.592       94.9 1.99e-22          1
    ## # ℹ 4 more variables: df$conf.low <dbl>, $conf.high <dbl>, $method <chr>,
    ## #   $alternative <chr>

To improve workflow, I wrote a function to perform a z-test and
construct a confidence interval under normal approximations of the data.

``` r
z_homicide = function(x, n){
  prop.test(x = x, n = n,
            p = 0.5, alternative = "two.sided") |> 
  broom::tidy()
}
```

Now I use this function to create a plot of the confidence interval for
every city.

``` r
df_homicide |> 
  mutate(z_out = map2(n_unsolved, n_homicide, z_homicide)) |> 
  unnest(z_out) |> 
  select(city_state, estimate, conf.low, conf.high) |> 
  mutate(city_state = fct_reorder(city_state, estimate)) |> 
  ggplot(aes(x = estimate, y = city_state)) + 
  geom_point() + 
  geom_errorbarh(aes(xmin = conf.low, xmax = conf.high)) + 
  labs(
      title = "Point and Interval Estimates of Homicide Closure",
      x = "Proportion of Unsolved Homicides",
      y = "City & State"
  )
```

<img src="p8105_hw5_drl2168_files/figure-gfm/create prop plot-1.png" width="90%" />

# Problem 2

I imported the data using `list.files` to identify each file of
interest, and then used `map` to apply `read_csv` to each file. I then
tidied the data.

``` r
df_study <- tibble(
  path = list.files("data/prob2")
) |> 
  mutate(
         id = str_sub(path, end = 6),
         group = str_sub(path, end = 3),
         path = str_c("data/prob2/", path),
         data = map(path, read_csv)
         ) |> 
  unnest(data) |> 
  pivot_longer(week_1:week_8,
               names_to = "week",
               values_to = "obs",
               names_prefix = "week_") |> 
  select(-path)
```

The final tidy dataframe consists of 160 observations of 4 variables:
subject `id`, `group`, `week`, and the outcome `obs`.

Now I will create a spaghetti plot to compare the control and
experimental arm.

``` r
df_study |> 
  ggplot(aes(x = week, y = obs, 
             group = id, color = group )) + 
  geom_line() + 
  labs(
    title = "Study Outcome Over Time",
    x = "Week",
    y = "Outcome",
    color = "Experimental Group"
  )
```

<img src="p8105_hw5_drl2168_files/figure-gfm/prob2 plot-1.png" width="90%" />

The outcome in the control group appears to be relatively constant over
time, while it increases over time in the experimental group. At week 1,
the two groups are relatively similar, though they appear different by
about week 4.

# Problem 3

Because the `map` and `map2` functions can only take 1-2 inputs, I’ll
create a function to generate a normal sample with only the true mean
`mu` as an input.

``` r
norm_samp = function(mu){
  out = rnorm(
    n = 30,
    mean = mu,
    sd = 5
  )
  return(out)
}
```

I will test this function in the $\mu = 0$ case.

``` r
df_sim0 <- tibble(
  mu = 0,
  iter = 1:5000
) |> 
  select(-iter) |> 
  mutate(sample = map(mu,norm_samp),
         test = map(sample, t.test),
         test = map(test, broom::tidy)) |> 
  unnest(test) |> 
  select(mu, estimate, p.value)
```
